{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "source: http://www.jakob-aungiers.com/articles/a/LSTM-Neural-Network-for-Time-Series-Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# only works on keras==1.2.2 tf==0.12.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "When building the dataset, if you skip every k points, the predictabiltiy will lose very quickly.\n",
    "It is not how many next points to predict is the key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import warnings\n",
    "import numpy as np\n",
    "from numpy import newaxis\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.models import Sequential\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = 'sp500.csv'\n",
    "seq_len = 50\n",
    "normalise_window = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' #Hide messy TensorFlow warnings\n",
    "warnings.filterwarnings(\"ignore\") #Hide messy Numpy warnings\n",
    "\n",
    "def load_data(filename, seq_len,next_n, normalise_window):\n",
    "    f = open(filename, 'rb').read()\n",
    "    data = f.decode().split('\\n')[:-1]\n",
    "\n",
    "    sequence_length = seq_len + 1\n",
    "    result = []\n",
    "    for index in range(0,len(data) - sequence_length,next_n):\n",
    "        result.append(data[index: index + sequence_length])\n",
    "    \n",
    "    if normalise_window:\n",
    "        result = normalise_windows(result)\n",
    "\n",
    "\n",
    "    np.random.seed(42)\n",
    "    \n",
    "    result = np.array(result)\n",
    "    np.random.shuffle(result)        \n",
    "\n",
    "    row = round(0.9 * result.shape[0])\n",
    "    train = result[:int(row), :]\n",
    "    np.random.shuffle(train)\n",
    "    x_train = train[:, :-next_n]\n",
    "    y_train = train[:, -next_n:]\n",
    "    x_test = result[int(row):, :-next_n]\n",
    "    y_test = result[int(row):, -next_n:]\n",
    "\n",
    "    x_train = np.reshape(x_train, (x_train.shape[0], x_train.shape[1], 1))\n",
    "    x_test = np.reshape(x_test, (x_test.shape[0], x_test.shape[1], 1))  \n",
    "\n",
    "    return [x_train, y_train, x_test, y_test]\n",
    "\n",
    "def normalise_windows(window_data):\n",
    "    normalised_data = []\n",
    "    for window in window_data:\n",
    "        normalised_window = [((float(p) / float(window[0])) - 1) for p in window]\n",
    "        normalised_data.append(normalised_window)\n",
    "    return normalised_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def MSE_2(y_true, y_pred):\n",
    "    return tf.sqrt(tf.reduce_mean(tf.squared_difference(y_true,y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def build_model(output_n=1):\n",
    "    model = Sequential()\n",
    "\n",
    "    model.add(LSTM(\n",
    "        input_dim= 1,\n",
    "        output_dim= 50,\n",
    "        return_sequences=False))\n",
    "    model.add(Dropout(0.4))\n",
    "\n",
    "    model.add(Dense(\n",
    "        output_dim= output_n))\n",
    "    model.add(Activation(\"linear\"))\n",
    "\n",
    "    start = time.time()\n",
    "    model.compile(loss=MSE_2, optimizer=\"rmsprop\")\n",
    "    print(\"> Compilation Time : \", time.time() - start)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Data Loaded. Compiling...\n",
      "('> Compilation Time : ', 0.030575990676879883)\n",
      "('X_train shape: ', (464, 43, 1))\n"
     ]
    }
   ],
   "source": [
    "output_num = 8\n",
    "X_train, y_train, X_test, y_test = load_data(filename, seq_len,output_num, True)\n",
    "\n",
    "print('> Data Loaded. Compiling...')\n",
    "\n",
    "model = build_model(output_num)\n",
    "print(\"X_train shape: \", X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 440 samples, validate on 24 samples\n",
      "Epoch 1/2\n",
      "440/440 [==============================] - 1s - loss: 0.0693 - val_loss: 0.0548\n",
      "Epoch 2/2\n",
      "440/440 [==============================] - 0s - loss: 0.0647 - val_loss: 0.0534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f7b60ee9550>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    batch_size=512,\n",
    "    nb_epoch=2,\n",
    "    validation_split=0.05)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from numpy import newaxis\n",
    "y_te_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(464, 8)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.plot(range(len(y_test[:,1])),y_te_pred[:,1])\n",
    "plt.plot(range(len(y_test[:,1])),y_test[:,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(464, 43, 1)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
